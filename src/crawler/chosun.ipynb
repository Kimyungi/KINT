{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from requests import request\n",
    "from requests.compat import urljoin, urlparse\n",
    "from requests.exceptions import HTTPError\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import re\n",
    "from requests.compat import urlparse, urljoin\n",
    "import sqlite3\n",
    "from requests import Session\n",
    "from datetime import datetime, timedelta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canfetch(url, agent='*', path='/'):\n",
    "    robot = RobotFileParser(urljoin(url, '/robots.txt'))\n",
    "    robot.read()\n",
    "    return robot.can_fetch(agent, urlparse(url)[2])\n",
    "    \n",
    "def download(url, params={}, headers={}, method='GET', limit=3):\n",
    "    try:\n",
    "        session = Session()\n",
    "        resp = session.request(method, url,\n",
    "                               params = params if method.upper() == 'GET' else '',\n",
    "                               data = params if method.upper() == 'POST' else '',\n",
    "                               headers = headers)\n",
    "        resp.raise_for_status()\n",
    "    except HTTPError as e:\n",
    "        if limit > 0 and e.response.status_code >= 500:\n",
    "            print(limit)\n",
    "            time.sleep(60) # Server Error이기 때문에 delay를 두고 실행하기 위해서 사용한다.\n",
    "            # 보통은 5분에 한 번꼴로 random하게 되도록 설정한다.\n",
    "            download(url, params, headers, method, limit-1)\n",
    "        else:\n",
    "            print('[{}] '.format(e.response.status_code) + url)\n",
    "            print(e.response.reason)\n",
    "            print(e.response.headers)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('news.db')\n",
    "cur = conn.cursor()\n",
    "cur.executescript('''\n",
    "    DROP TABLE IF EXISTS head;\n",
    "    CREATE TABLE head(\n",
    "        pk INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        head TEXT NOT NULL,\n",
    "        cdate TEXT NOT NULL,\n",
    "        wdate TEXT NOT NULL,\n",
    "        ref INTEGER NOT NULL,\n",
    "        page INTEGER NOT NULL\n",
    "    );\n",
    "''')\n",
    "\n",
    "cur.executescript('''\n",
    "    DROP TABLE IF EXISTS history;\n",
    "    CREATE TABLE history(\n",
    "        pk INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        seen TEXT NOT NULL,\n",
    "        ref INTEGER NOT NULL\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seen = list()\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36',\n",
    "          'cookie': '_ga=GA1.2.155331207.1590371425; _ss_pp_id=6d5c749e45df5fc2e3f1588636203804; __gads=ID=32309e63460e7bec:T=1590587589:S=ALNI_MbT83O-w-NBELV4M2sBrRwfoU4ZtQ; PCID=15946360484484587904430; OAX=gIYFPF8MNw4AAKeC; __utmz=222464713.1594814175.4.2.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); adfit_sdk_id=27c83848-9b3d-4f52-bd4d-abbd9d93a0ef; __utma=222464713.155331207.1590371425.1594814175.1595161152.5; _td=8dc8df98-07d4-4639-aa8b-f5bcd75c27b4; _cb_ls=1; _cb=BwJni3Czf8gSDbs39n; _gid=GA1.2.780937476.1597652887; _chartbeat2=.1597235265832.1597657270138.100001.P_loMBN6GXFO-uI2DZimj6lyt7i.1; _gat=1; _gat_chosun_total=1',\n",
    "          'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7,ja;q=0.6'}\n",
    "\n",
    "# 시간변수 만들기\n",
    "start_date = datetime.strptime('20190817', '%Y%m%d') \n",
    "end_date = datetime.today()\n",
    "\n",
    "str_date_list = [] \n",
    "while start_date.strftime('%Y%m%d') != end_date.strftime('%Y%m%d'): \n",
    "    str_date_list.append(start_date.strftime('%Y%m%d')) \n",
    "    start_date += timedelta(days=1)\n",
    "\n",
    "url = 'https://news.chosun.com/svc/list_in/list_title.html?indate='\n",
    "urls = list()\n",
    "for i in str_date_list:\n",
    "    u = url + i + '&source=1&pn=1'\n",
    "    urls.append(u)    \n",
    "\n",
    "count = 0\n",
    "    \n",
    "while urls:\n",
    "    try:\n",
    "        count += 1\n",
    "        seed = urls.pop(-1)\n",
    "\n",
    "        resp = download(seed, headers=headers)\n",
    "        dom = BeautifulSoup(resp.content.decode('utf-8','replace'), 'html.parser')\n",
    "        seen.append(seed)\n",
    "        cur.execute('''\n",
    "            INSERT INTO history(seen, ref) VALUES(?, 1000)\n",
    "        ''', [seed])\n",
    "        \n",
    "        for _ in [_['href'] for _ in dom.select('#list_body_id > div.paginate > ul > li > a') \n",
    "                  if _.has_attr('href') or _.has_attr('next')]:\n",
    "            newUrls = urljoin(seed, _)\n",
    "            if newUrls not in urls and newUrls not in seen:\n",
    "                urls.append(newUrls)\n",
    "        \n",
    "        if dom.select('#list_body_id > div.list_content > dl > dt') != None:\n",
    "            head = [_.text.strip() for _ in dom.select('#list_body_id > div.list_content > dl > dt') ]\n",
    "            wdate = [_.text.strip() for _ in dom.select('#list_body_id > div.list_content > dl > dd.date_author > span.date') ]\n",
    "            cdate = str(datetime.now()).split('.')[0]\n",
    "            page = re.search('pn=(\\d+)', urlparse(seed).query).group(1)\n",
    "            if len(head)==len(wdate):\n",
    "                for _ in range(0,len(head)):\n",
    "                    cur.execute('''\n",
    "                        INSERT INTO head(head, cdate, wdate, page, ref) VALUES(?,?,?,?,1000)\n",
    "                        ''', [head[_], wdate[_], cdate, page])\n",
    "                    conn.commit()\n",
    "\n",
    "        if count%100 == 0:\n",
    "                print(count)\n",
    "     \n",
    "    except Exception as e:\n",
    "            print('Error',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
