{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Stopwords 처리\n",
    "punc = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "pattern1 = re.compile(r'[{}]'.format(re.escape(punc))) # punctuation 제거\n",
    "pattern2 = re.compile(r'[.]{2,}') # . 2개 이상이면, 1개로 바꾸기\n",
    "pattern3 = re.compile(r'([ㄱ-ㅎㅏ-ㅣ])\\1') # ㅋㅋ, ㄷㄷㄷ과 같은거 제거\n",
    "pattern4 = re.compile(r'[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ. ]') # 특수문자 제거\n",
    "pattern5 = re.compile(r'\\s{2,}') # white space 1개로 바꾸기.\n",
    "\n",
    "def cleaning(df):\n",
    "    return pattern5.sub(' ', \n",
    "              pattern4.sub('',\n",
    "               pattern3.sub('',\n",
    "                pattern2.sub('.',\n",
    "                 pattern1.sub('', df)))))\n",
    "\n",
    "def extract_nouns(df):\n",
    "    noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "    nouns = noun_extractor.train_extract([df])\n",
    "    words = defaultdict(lambda:0)\n",
    "    for k, v in nouns.items():\n",
    "        if len(k) > 1:\n",
    "            words[k] = v\n",
    "    return sorted(words.items(),key=lambda _:_[1], reverse=True)\n",
    "\n",
    "def search_dict(nouns):\n",
    "    # 사전 검색 결과 없는 단어 추출\n",
    "    conn = sqlite3.connect('kr_korean.db')\n",
    "    cur = conn.cursor()\n",
    "    data = pd.read_sql('SELECT word FROM kr WHERE part=\"명사\"', conn)\n",
    "    data = ' '.join(data['word'])\n",
    "    return pd.DataFrame([_ for _ in nouns if _[0] not in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 27791 from 1 sents. mem=0.478 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=55861, mem=0.477 Gb\n",
      "[Noun Extractor] batch prediction was completed for 7035 words\n",
      "[Noun Extractor] checked compounds. discovered 1139 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 3172 -> 2914\n",
      "[Noun Extractor] postprocessing ignore_features : 2914 -> 2861\n",
      "[Noun Extractor] postprocessing ignore_NJ : 2861 -> 2852\n",
      "[Noun Extractor] 2852 nouns (1139 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=0.477 Gb                    \n",
      "[Noun Extractor] 45.96 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Humor.db')\n",
    "cur = conn.cursor()\n",
    "df = pd.read_sql('SELECT head FROM head',conn)\n",
    "df = ' '.join(df['head'])\n",
    "df = cleaning(df)\n",
    "nouns = extract_nouns(df)\n",
    "new_word = search_dict(nouns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
