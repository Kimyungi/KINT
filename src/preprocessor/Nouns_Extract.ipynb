{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Stopwords 처리\n",
    "punc = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "pattern1 = re.compile(r'[{}]'.format(re.escape(punc))) # punctuation 제거\n",
    "pattern2 = re.compile(r'[.]{2,}') # . 2개 이상이면, 1개로 바꾸기\n",
    "pattern3 = re.compile(r'([ㄱ-ㅎㅏ-ㅣ])\\1') # ㅋㅋ, ㄷㄷㄷ과 같은거 제거\n",
    "pattern4 = re.compile(r'[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ. ]') # 특수문자 제거\n",
    "pattern5 = re.compile(r'\\s{2,}') # white space 1개로 바꾸기.\n",
    "\n",
    "def cleaning(df):\n",
    "    return pattern5.sub('', \n",
    "              pattern4.sub('.',\n",
    "               pattern3.sub('',\n",
    "                pattern2.sub('',\n",
    "                 pattern1.sub(' ', df)))))\n",
    "\n",
    "def extract_nouns(df):\n",
    "    noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "    nouns = noun_extractor.train_extract([df])\n",
    "    words = defaultdict(lambda:0)\n",
    "    for k, v in nouns.items():\n",
    "        if len(k) > 1:\n",
    "            words[k] = v\n",
    "    return sorted(words.items(),key=lambda _:_[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 28125 from 1 sents. mem=0.263 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=51455, mem=0.310 Gb\n",
      "[Noun Extractor] batch prediction was completed for 7609 words\n",
      "[Noun Extractor] checked compounds. discovered 1523 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 3391 -> 3070\n",
      "[Noun Extractor] postprocessing ignore_features : 3070 -> 3018\n",
      "[Noun Extractor] postprocessing ignore_NJ : 3018 -> 3010\n",
      "[Noun Extractor] 3010 nouns (1523 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=0.334 Gb                    \n",
      "[Noun Extractor] 46.29 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Humor.db')\n",
    "cur = conn.cursor()\n",
    "df = pd.read_sql('SELECT head FROM head',conn)\n",
    "df = ' '.join(df['head'])\n",
    "df = cleaning(df)\n",
    "nouns = extract_nouns(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
