{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 사용법 (예문 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  sent.db에서 신어에 해당하는 예문을 가져온뒤 Bidirectional GRU Model을 사용하여 예문 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import Example\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('sent.db') # sent.db 연결\n",
    "# sent.db에는 신어, 신어가 포함된 예문이 들어 있음\n",
    "temp = pd.read_sql('SELECT * FROM sent', conn)  # sent.db에서 전체 데이터를 temp에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예문 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sentence = list()\n",
    "example_sentence = list()\n",
    "# 모든 신어에 대해 반복한다.\n",
    "for _ in range(len(temp['0'])):\n",
    "    sent = temp['0'][_] # 신어가 들어있는 문장\n",
    "    sent = sent.split('  ') # 각 문장을 더블스페이스 단위로 분리\n",
    "    sent = [_+'/' for _ in sent] # 분리된 문장을 '/' 로 구분\n",
    "    words = {temp['index'][_]: 1.0} # 해당 신어를 하나의 단어로 인식할 수 있도록 dict 생성\n",
    "    \n",
    "    lgen = Example.generator_ltokenizer(words, sent)\n",
    "    # Example 모듈에서 soynlp의 ltokenizer를 사용하여 cohesion_forward 값을 기준으롬 명사 추출\n",
    "    sentences = [[word for word in lgen.tokenizer(sentence)] for sentence in sent]\n",
    "    # 각 신어의 예문을 토큰화 시켜서 sentences에 저장\n",
    "    lgen.train_word_model(sentences) # Word2Vec 모델 Training\n",
    "    X,y = lgen.create_var(sentences) # X, y 값 생성\n",
    "    lgen.model() # Bidirectional GRU Model 생성\n",
    "    lgen.model.fit(X, y, epochs=70, verbose=2) # Model 학습\n",
    "    \n",
    "    temp_sent = lgen.sentence_generation(temp['index'][_], 22) # 각단어에 해당하는 22 단어로 이루어진 문장 생성\n",
    "    result = ''\n",
    "    for _ in temp_sent: # temp_sent에서 /로 끝나면 break하여 한 문장으로 끊어내기\n",
    "        if _ == '/':\n",
    "            break\n",
    "        else:\n",
    "            result = result + '' + _\n",
    "    full_sentence.append(temp_sent)\n",
    "    example_sentence.append(result) # 결과를 example_sentence에 저장\n",
    "pd.DataFrame(example_sentence).to_excel('example.xlsx') # excel에 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
