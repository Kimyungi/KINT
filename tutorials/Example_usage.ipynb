{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예문 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  sent.db에서 신어에 해당하는 예문을 가져온뒤 Bidirectional GRU Model을 사용하여 예문 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import Example\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('sent.db') # sent.db 연결\n",
    "# sent.db에는 신어, 신어가 포함된 예문이 들어 있음\n",
    "temp = pd.read_sql('SELECT * FROM sent', conn)  # sent.db에서 전체 데이터를 temp에 저장\n",
    "\n",
    "full_sentence = list()\n",
    "example_sentence = list()\n",
    "for _ in range(len(temp['0'])):\n",
    "    sent = temp['0'][_] # _번째 문장들\n",
    "    sent = sent.split('  ') # _번째 문장들은 더블스페이스 단위로 분리\n",
    "    sent = [_+'/' for _ in sent] # 분리된 문장을 '/' 로 구분\n",
    "    words = {temp['index'][_]: 1.0} # tme['index']의 _번째 행을 1로저장하는 dict 생성\n",
    "    \n",
    "    lgen = Example.generator_ltokenizer(words, sent) # Example 모듈에서 ltokenizer사용\n",
    "                                                     # cohesion_forward 값을 기준으롬 명사 추출\n",
    "    sentences = [[word for word in lgen.tokenizer(sentence)] for sentence in sent]\n",
    "    # 각 신어의 예문을 토큰화 시켜서 sentences에 저장\n",
    "    lgen.train_word_model(sentences) # 모델학습\n",
    "    X,y = lgen.create_var(sentences) # X, y 값 지정\n",
    "    lgen.model()\n",
    "    lgen.model.fit(X, y, epochs=70, verbose=2)\n",
    "    \n",
    "    temp_sent = lgen.sentence_generation(temp['index'][_], 22) # 각단어에 해당하는 22 단어로 이루어진 문장 생성\n",
    "    result = ''\n",
    "    for _ in temp_sent: # temp_sent에서 /로 끝나면 break\n",
    "        if _ == '/':\n",
    "            break\n",
    "        else:\n",
    "            result = result + '' + _\n",
    "    full_sentence.append(temp_sent)\n",
    "    example_sentence.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
